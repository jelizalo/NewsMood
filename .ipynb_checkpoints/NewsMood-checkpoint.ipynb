{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NewsMood\n",
    "\n",
    "In this assignment, you'll create a Python script to perform a sentiment analysis of the Twitter activity of various news oulets, and to present your findings visually.\n",
    "\n",
    "Your final output should provide a visualized summary of the sentiments expressed in Tweets sent out by the following news organizations: BBC, CBS, CNN, Fox, and New York times.\n",
    "\n",
    "The first plot will be and/or feature the following:\n",
    "\n",
    "Be a scatter plot of sentiments of the last 100 tweets sent out by each news organization, ranging from -1.0 to 1.0, where a score of 0 expresses a neutral sentiment, -1 the most negative sentiment possible, and +1 the most positive sentiment possible.\n",
    "Each plot point will reflect the compound sentiment of a tweet.\n",
    "Sort each plot point by its relative timestamp.\n",
    "The second plot will be a bar plot visualizing the overall sentiments of the last 100 tweets from each organization. For this plot, you will again aggregate the compound sentiments analyzed by VADER.\n",
    "\n",
    "The tools of the trade you will need for your task as a data analyst include the following: tweepy, pandas, matplotlib, seaborn, textblob, and VADER.\n",
    "\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "Pull last 100 tweets from each outlet.\n",
    "Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet.\n",
    "Pull into a DataFrame the tweet's source acount, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "Export the data in the DataFrame into a CSV file.\n",
    "Save PNG images for each plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Trend 1:\n",
    "\n",
    "Trend 2: \n",
    "\n",
    "Trend 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob, Word, Blobber\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'consumer_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-36fe1901099d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Setup Tweepy API Authentication\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOAuthHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsumer_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumer_secret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_access_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccess_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_token_secret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'consumer_key' is not defined"
     ]
    }
   ],
   "source": [
    "# Twitter API keys\n",
    "import config\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the news stations\n",
    "target_terms = [\"@BBCNews\", \"@CBSNews\", \"@CNN\", \"@FoxNews\", \"@nytimes\"]\n",
    "\n",
    "# Variables for holding sentiments\n",
    "sentiments = []\n",
    "\n",
    "# Loop through each news station to get the recent 100 tweets\n",
    "for x in range(1):\n",
    "\n",
    "    # Loop through all news stations\n",
    "    for target in target_terms:\n",
    "\n",
    "        public_tweets = api.user_timeline(target)\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "\n",
    "            # Add sentiments for each tweet into an array\n",
    "            sentiments.append({\"Date\": tweet[\"created_at\"],\n",
    "                               \"Screen_Name\": tweet['user']['screen_name'],\n",
    "                               \"Compound\": compound,\n",
    "                               \"Positive\": pos,\n",
    "                               \"Negative\": neu,\n",
    "                               \"Neutral\": neg})\n",
    "\n",
    "\n",
    "#Generated dataframe containing sentiment for Media Sources\n",
    "df_sentiment_analysis= pd.DataFrame(sentiments) \n",
    "\n",
    "df_sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create CSV from dataframe\n",
    "df_sentiment_analysis.to_csv('NewsSentimentAnalysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sentiments of the last 100 tweets\n",
    "\n",
    "scatter_plot = sns.lmplot('Date', 'Compound', data=df_sentiment_analysis, aspect=2, fit_reg=False, hue='Screen_Name', legend=False).add_legend(loc=\"best\", title = \"Media Sources\")\n",
    "scatter_plot = (scatter_plot.set_axis_labels(\"Tweet Ago\",\"Tweet Polarity\").set(xlim=(0,100),ylim=(-1,1)))\n",
    "\n",
    "\n",
    "#scatter_plot = sns.FacetGrid(df_sentiment_analysis, 'Date', hue=\"Screen_Name\")\n",
    "#scatter_plot = (scatter_plot.map(plt.scatter, 'Date', 'Compound' , edgecolor=\"w\").add_legend(loc=\"best\"))\n",
    "\n",
    "#fg.map(plt.scatter, 'tweet_date_list', 'compound_list', s= 1,edgecolors=\"black\", alpha=0.75).add_legend(loc=\"best\")\n",
    "\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%m/%d/%Y\")\n",
    "plt.title('Sentiment Analysis of Media Tweets ({})'.format(now),fontsize=(14))\n",
    "plt.grid()\n",
    "\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(\"SentimentAnalysis.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Overall Media Sentiment based on Twitter table\n",
    "Twitter_summary = df_sentiment_analysis.groupby([\"Screen_Name\"])[\"Compound\"].mean().reset_index()\n",
    "\n",
    "\n",
    "# Renaming Columns\n",
    "Twitter_summary.rename_axis({'Screen_Name': 'Media Sources',\n",
    "                                                 'Compound':  'Average Compound'},axis=1,inplace=True)\n",
    "\n",
    "# Output Twitter Table dataframe\n",
    "Twitter_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar graph\n",
    "#plt.bar(Twitter_summary['Media Sources'], Twitter_summary['Average Compound'], color='r', alpha=0.5, align=\"edge\")\n",
    "\n",
    "ax = sns.barplot(x=Twitter_summary['Media Sources'], y=Twitter_summary['Average Compound'], hue=Twitter_summary['Media Sources'], data=Twitter_summary,\n",
    "                 order=[\"BBCNews\", \"CBSNews\", \"CNN\", \"FoxNews\", \"nytimes\"])\n",
    "\n",
    "# Sets the y limits of the current chart\n",
    "plt.ylim(-1,1)\n",
    "\n",
    "# Give our chart some labels and a tile\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%m/%d/%Y\")\n",
    "plt.title('Overall Media Sentiment Analysis based on Twitter ({})'.format(now),fontsize=(14))\n",
    "plt.xlabel(\"Media Sources\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "\n",
    "# Print our chart to the screen and save image\n",
    "plt.show()\n",
    "plt.savefig(\"OverallSentimentAnalysisTwitter.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
